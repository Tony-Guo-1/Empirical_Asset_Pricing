{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6937131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc # Use gc.collect() to release memory usage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed6aa5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read publicly available data (>4mil entries)\n",
    "data = pd.read_csv('GKX_20201231.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e66501",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date, end_date = 19570131, 20161231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cdbba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all the data that will be used for recursive training\n",
    "data = data[(data['DATE'] >= start_date) & (data['DATE'] <= end_date)].reset_index(drop=True)\n",
    "\n",
    "# Change date format for grouping later; offsets.MonthEnd(0) means dates need not be adjusted. They were adjusted in the dataset\n",
    "data['DATE'] = pd.to_datetime(data['DATE'], format='%Y%m%d') + pd.offsets.MonthEnd(0)\n",
    "\n",
    "# In case \"data\" is needed later\n",
    "# data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89dbbafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics = list(set(data.columns).difference({'permno','DATE','SHROUT','mve0','sic2','RET','prc'}))\n",
    "characteristics.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "368e4669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['prc', 'mve0', 'sic2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Fill NA entries with cross-sectional median\n",
    "for ch in characteristics:\n",
    "    data[ch] = data.groupby('DATE')[ch].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Fill the rest with 0\n",
    "for ch in characteristics:\n",
    "    data[ch] = data[ch].fillna(0)\n",
    "\n",
    "print(data.columns[data.isnull().sum() != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1245958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load macroeconomic predictors data. There are eight of them\n",
    "data_ma = pd.read_excel('PredictorData2022.xlsx')\n",
    "# The format of dates in macro predictors is YYYYMM instead of YYYYMMDD\n",
    "data_ma = data_ma[(data_ma['yyyymm'] >= start_date//100) & (data_ma['yyyymm'] <= end_date//100)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065c51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct predictors\n",
    "# Index, ntis, tbl, svar are given in the dataset. The remaining four are calculated using other columns\n",
    "ma_predictors = ['dp_sp','ep_sp','bm_sp','ntis','tbl','tms','dfy','svar']\n",
    "\n",
    "# data_ma['Index'] is already float64\n",
    "# data_ma['Index'] = data_ma['Index'].str.replace(',','').astype('float64')\n",
    "data_ma['dp_sp'] = data_ma['D12'] / data_ma['Index']\n",
    "data_ma['ep_sp'] = data_ma['E12'] / data_ma['Index']\n",
    "data_ma.rename({'b/m':'bm_sp'},axis=1,inplace=True)\n",
    "data_ma['tms'] = data_ma['lty'] - data_ma['tbl']\n",
    "data_ma['dfy'] = data_ma['BAA'] - data_ma['AAA']\n",
    "\n",
    "# This removes all the intermediate columns and leaves only the eight predictors, date, and risk-free rate column\n",
    "data_ma = data_ma[['yyyymm'] + ma_predictors + ['Rfree']]\n",
    "data_ma['yyyymm'] = pd.to_datetime(data_ma['yyyymm'], format='%Y%m') + pd.offsets.MonthEnd(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f3ce3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>dp_sp</th>\n",
       "      <th>ep_sp</th>\n",
       "      <th>bm_sp</th>\n",
       "      <th>ntis</th>\n",
       "      <th>tbl</th>\n",
       "      <th>tms</th>\n",
       "      <th>dfy</th>\n",
       "      <th>svar</th>\n",
       "      <th>Rfree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1957-01-31</td>\n",
       "      <td>0.038834</td>\n",
       "      <td>0.076178</td>\n",
       "      <td>0.567243</td>\n",
       "      <td>0.027992</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957-02-28</td>\n",
       "      <td>0.040068</td>\n",
       "      <td>0.078672</td>\n",
       "      <td>0.584994</td>\n",
       "      <td>0.030173</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1957-03-31</td>\n",
       "      <td>0.039220</td>\n",
       "      <td>0.077080</td>\n",
       "      <td>0.599819</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1957-04-30</td>\n",
       "      <td>0.037822</td>\n",
       "      <td>0.074479</td>\n",
       "      <td>0.576098</td>\n",
       "      <td>0.027421</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1957-05-31</td>\n",
       "      <td>0.036475</td>\n",
       "      <td>0.071966</td>\n",
       "      <td>0.564039</td>\n",
       "      <td>0.028849</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.040704</td>\n",
       "      <td>0.315197</td>\n",
       "      <td>-0.030782</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>0.020766</td>\n",
       "      <td>0.041088</td>\n",
       "      <td>0.316794</td>\n",
       "      <td>-0.032603</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>0.021283</td>\n",
       "      <td>0.042758</td>\n",
       "      <td>0.319688</td>\n",
       "      <td>-0.029034</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>0.020682</td>\n",
       "      <td>0.042173</td>\n",
       "      <td>0.303286</td>\n",
       "      <td>-0.027452</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>0.020413</td>\n",
       "      <td>0.042232</td>\n",
       "      <td>0.293479</td>\n",
       "      <td>-0.025104</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        yyyymm     dp_sp     ep_sp     bm_sp      ntis     tbl     tms  \\\n",
       "0   1957-01-31  0.038834  0.076178  0.567243  0.027992  0.0311  0.0017   \n",
       "1   1957-02-28  0.040068  0.078672  0.584994  0.030173  0.0310  0.0018   \n",
       "2   1957-03-31  0.039220  0.077080  0.599819  0.026600  0.0308  0.0023   \n",
       "3   1957-04-30  0.037822  0.074479  0.576098  0.027421  0.0307  0.0038   \n",
       "4   1957-05-31  0.036475  0.071966  0.564039  0.028849  0.0306  0.0042   \n",
       "..         ...       ...       ...       ...       ...     ...     ...   \n",
       "715 2016-08-31  0.020653  0.040704  0.315197 -0.030782  0.0030  0.0156   \n",
       "716 2016-09-30  0.020766  0.041088  0.316794 -0.032603  0.0029  0.0167   \n",
       "717 2016-10-31  0.021283  0.042758  0.319688 -0.029034  0.0033  0.0187   \n",
       "718 2016-11-30  0.020682  0.042173  0.303286 -0.027452  0.0045  0.0222   \n",
       "719 2016-12-31  0.020413  0.042232  0.293479 -0.025104  0.0051  0.0221   \n",
       "\n",
       "        dfy      svar   Rfree  \n",
       "0    0.0072  0.000902  0.0027  \n",
       "1    0.0080  0.001056  0.0024  \n",
       "2    0.0077  0.000330  0.0023  \n",
       "3    0.0077  0.000302  0.0025  \n",
       "4    0.0078  0.000482  0.0026  \n",
       "..      ...       ...     ...  \n",
       "715  0.0092  0.000279  0.0002  \n",
       "716  0.0090  0.001673  0.0002  \n",
       "717  0.0087  0.000364  0.0002  \n",
       "718  0.0085  0.000946  0.0001  \n",
       "719  0.0077  0.000524  0.0003  \n",
       "\n",
       "[720 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b237896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummies for SIC code\n",
    "def get_sic_dummies(data):\n",
    "    sic_dummies = pd.get_dummies(data['sic2'].fillna(999).astype(int), prefix='sic').drop('sic_999', axis=1)\n",
    "    data = pd.concat([data, sic_dummies], axis=1)\n",
    "    data.drop(['prc', 'SHROUT', 'mve0', 'sic2'], inplace=True, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f13d1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762139, 171)\n"
     ]
    }
   ],
   "source": [
    "data = get_sic_dummies(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50498cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training 1957 - 1974\n",
    "# validation 1975 - 1986\n",
    "# test 1987 - 2016\n",
    "start_val = np.datetime64('1975-01-31')\n",
    "start_test = np.datetime64('1987-01-31')\n",
    "end_test = np.datetime64('1987-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccaf7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactions(data, data_ma, characteristics, ma_predictors):\n",
    "\n",
    "    data_ma_long = pd.merge(data[['DATE']], data_ma, left_on='DATE', right_on='yyyymm', how='left').reset_index(drop=True)\n",
    "    \n",
    "    # Important! Reset index so that we can construct the interaction columns correctly\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    # Change RET to excess return\n",
    "    data.loc[:, 'RET'] = data.loc[:, 'RET'] - data_ma_long.loc[:, 'Rfree']\n",
    "    \n",
    "    # Data PRE-processing: cross-sectional rank transformation\n",
    "    # data has all columns (including DATE) and all rows\n",
    "    for fc in characteristics:\n",
    "        data[fc] = data.groupby('DATE')[fc].rank()\n",
    "        data[fc] = data.groupby('DATE')[fc].transform(lambda x: ((2 * (x - x.min())) / (x.max() - x.min())) - 1\n",
    "                                                     if x.max() - x.min() != 0 else 0)\n",
    "    \n",
    "    # Construct interactions\n",
    "    interactions = []\n",
    "    for fc in characteristics:\n",
    "        for mp in ma_predictors:\n",
    "            data[fc + '*' + mp] = data.loc[:, fc] * data_ma_long.loc[:, mp]\n",
    "            interactions.append(fc + '*' + mp)\n",
    "    \n",
    "    # Also normalize the interactions so there are no super small or large numbers\n",
    "    for item in interactions:\n",
    "        data[item] = data.groupby('DATE')[item].transform(lambda x: ((2 * (x - x.min())) / (x.max() - x.min())) - 1\n",
    "                                                     if x.max() - x.min() != 0 else 0)\n",
    "        \n",
    "    # 94 (chars) * 8 (macro) + 94 (chars) + 74 (industry) = 920\n",
    "    features = list(set(data.columns).difference({'permno', 'DATE', 'RET'}))\n",
    "    \n",
    "    # Get x and y\n",
    "    x = data[features]\n",
    "    y = pd.DataFrame(data['RET'], columns=['RET'])\n",
    "    \n",
    "    # Get top 1k\n",
    "    x_t_sorted = data.sort_values(by='mvel1', ascending=False).groupby('DATE').head(1000).reset_index(drop=True)\n",
    "    x_t = x_t_sorted[features]\n",
    "    y_t = pd.DataFrame(x_t_sorted['RET'], columns=['RET'])\n",
    "    \n",
    "    # Get bot 1k; without ascending=False, ordered in ascending order\n",
    "    x_b_sorted = data.sort_values(by='mvel1').groupby('DATE').head(1000).reset_index(drop=True)\n",
    "    x_b = x_b_sorted[features]\n",
    "    y_b = pd.DataFrame(x_b_sorted['RET'], columns=['RET'])\n",
    "    \n",
    "    print(x.shape, y.shape, x_t.shape, y_t.shape, x_b.shape, y_b.shape)\n",
    "    return x, y, x_t, y_t, x_b, y_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b5fe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(479467, 920) (479467, 1) (216000, 920) (216000, 1) (216000, 920) (216000, 1)\n",
      "(773887, 920) (773887, 1) (144000, 920) (144000, 1) (144000, 920) (144000, 1)\n",
      "(83323, 920) (83323, 1) (12000, 920) (12000, 1) (12000, 920) (12000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_train_t, y_train_t, x_train_b, y_train_b = interactions(data[data['DATE'] < start_val], \n",
    "                                                                            data_ma[data_ma['yyyymm'] < start_val],\n",
    "                                                                            characteristics, ma_predictors)\n",
    "\n",
    "x_val, y_val, x_val_t, y_val_t, x_val_b, y_val_b = interactions(data[(data['DATE'] < start_test) & (data['DATE'] >= start_val)],\n",
    "                                                                data_ma[(data_ma['yyyymm'] < start_test) & (data_ma['yyyymm'] >= start_val)],\n",
    "                                                                characteristics, ma_predictors)\n",
    "\n",
    "x_test, y_test, x_test_t, y_test_t, x_test_b, y_test_b = interactions(data[(data['DATE'] >= start_test) & (data['DATE'] <= end_test)],\n",
    "                                                                      data_ma[(data_ma['yyyymm'] >= start_test) & (data_ma['yyyymm'] <= end_test)],\n",
    "                                                                      characteristics, ma_predictors)\n",
    "gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0f87462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check whether there are invalid data points before proceeding to train\n",
    "print(x_train.columns[x_train.isnull().sum() != 0])\n",
    "print(x_val.columns[x_val.isnull().sum() != 0])\n",
    "print(x_test.columns[x_test.isnull().sum() != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fda81d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_turn*ep_sp</th>\n",
       "      <th>roeq</th>\n",
       "      <th>sic_40</th>\n",
       "      <th>cashpr*svar</th>\n",
       "      <th>ep*ep_sp</th>\n",
       "      <th>chtx*ep_sp</th>\n",
       "      <th>nincr*tms</th>\n",
       "      <th>beta*tms</th>\n",
       "      <th>age*tbl</th>\n",
       "      <th>hire*dfy</th>\n",
       "      <th>...</th>\n",
       "      <th>chempia*tms</th>\n",
       "      <th>sin*tbl</th>\n",
       "      <th>grltnoa</th>\n",
       "      <th>pchcapx_ia*dp_sp</th>\n",
       "      <th>aeavol*bm_sp</th>\n",
       "      <th>rd*tbl</th>\n",
       "      <th>sic_31</th>\n",
       "      <th>chatoia*dfy</th>\n",
       "      <th>mom6m</th>\n",
       "      <th>egr*tbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.021968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.378119</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.623687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.817658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.687140</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.272206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.234165</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.680993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.155470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452975</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.090735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474088</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 920 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   std_turn*ep_sp  roeq  sic_40  cashpr*svar  ep*ep_sp  chtx*ep_sp  nincr*tms  \\\n",
       "0       -0.021968   0.0       0          0.0       0.0         0.0        0.0   \n",
       "1        0.623687   0.0       0          0.0       0.0         0.0        0.0   \n",
       "2        0.272206   0.0       0          0.0       0.0         0.0        0.0   \n",
       "3        0.680993   0.0       0          0.0       0.0         0.0        0.0   \n",
       "4       -0.090735   0.0       0          0.0       0.0         0.0        0.0   \n",
       "\n",
       "   beta*tms  age*tbl  hire*dfy  ...  chempia*tms  sin*tbl  grltnoa  \\\n",
       "0  0.197697      0.0       0.0  ...          0.0      0.0      0.0   \n",
       "1 -0.817658      0.0       0.0  ...          0.0      0.0      0.0   \n",
       "2  0.117083      0.0       0.0  ...          0.0      0.0      0.0   \n",
       "3 -0.155470      0.0       0.0  ...          0.0      0.0      0.0   \n",
       "4  0.412668      0.0       0.0  ...          0.0      0.0      0.0   \n",
       "\n",
       "   pchcapx_ia*dp_sp  aeavol*bm_sp  rd*tbl  sic_31  chatoia*dfy     mom6m  \\\n",
       "0               0.0           0.0     0.0       0          0.0 -0.378119   \n",
       "1               0.0           0.0     0.0       0          0.0 -0.687140   \n",
       "2               0.0           0.0     0.0       0          0.0 -0.234165   \n",
       "3               0.0           0.0     0.0       0          0.0  0.452975   \n",
       "4               0.0           0.0     0.0       0          0.0  0.474088   \n",
       "\n",
       "   egr*tbl  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "\n",
       "[5 rows x 920 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "882ccca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_turn*ep_sp</th>\n",
       "      <th>roeq</th>\n",
       "      <th>sic_40</th>\n",
       "      <th>cashpr*svar</th>\n",
       "      <th>ep*ep_sp</th>\n",
       "      <th>chtx*ep_sp</th>\n",
       "      <th>nincr*tms</th>\n",
       "      <th>beta*tms</th>\n",
       "      <th>age*tbl</th>\n",
       "      <th>hire*dfy</th>\n",
       "      <th>...</th>\n",
       "      <th>chempia*tms</th>\n",
       "      <th>sin*tbl</th>\n",
       "      <th>grltnoa</th>\n",
       "      <th>pchcapx_ia*dp_sp</th>\n",
       "      <th>aeavol*bm_sp</th>\n",
       "      <th>rd*tbl</th>\n",
       "      <th>sic_31</th>\n",
       "      <th>chatoia*dfy</th>\n",
       "      <th>mom6m</th>\n",
       "      <th>egr*tbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.465377</td>\n",
       "      <td>0.552708</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.274417</td>\n",
       "      <td>-0.622961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030813</td>\n",
       "      <td>-0.124664</td>\n",
       "      <td>0.869120</td>\n",
       "      <td>0.816868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833798</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.643660</td>\n",
       "      <td>0.666391</td>\n",
       "      <td>0.762082</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.728137</td>\n",
       "      <td>0.396464</td>\n",
       "      <td>-0.506555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.506945</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.708858</td>\n",
       "      <td>-0.957051</td>\n",
       "      <td>-0.996706</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.737403</td>\n",
       "      <td>-0.712605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.505316</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.521923</td>\n",
       "      <td>0.870159</td>\n",
       "      <td>0.580752</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.884432</td>\n",
       "      <td>-0.225059</td>\n",
       "      <td>-0.926912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030813</td>\n",
       "      <td>-0.122597</td>\n",
       "      <td>-0.012335</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003717</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.372273</td>\n",
       "      <td>0.003407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.663751</td>\n",
       "      <td>-0.600248</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.618418</td>\n",
       "      <td>-0.329754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030813</td>\n",
       "      <td>-0.191234</td>\n",
       "      <td>0.332636</td>\n",
       "      <td>0.617838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.624652</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>-0.513564</td>\n",
       "      <td>0.770756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871201</td>\n",
       "      <td>0.041249</td>\n",
       "      <td>-0.629194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.888877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030813</td>\n",
       "      <td>-0.582799</td>\n",
       "      <td>-0.012335</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003717</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305903</td>\n",
       "      <td>0.003407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 920 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   std_turn*ep_sp      roeq  sic_40  cashpr*svar  ep*ep_sp  chtx*ep_sp  \\\n",
       "0       -0.465377  0.552708       0    -0.274417 -0.622961    0.000000   \n",
       "1       -0.506945 -1.000000       0    -0.708858 -0.957051   -0.996706   \n",
       "2        0.000103  0.000000       0     0.003510  0.003510    0.000000   \n",
       "3       -0.663751 -0.600248       0    -0.618418 -0.329754    0.000000   \n",
       "4       -0.888877  0.000000       0     0.003510  0.003510    0.000000   \n",
       "\n",
       "   nincr*tms  beta*tms   age*tbl  hire*dfy  ...  chempia*tms  sin*tbl  \\\n",
       "0  -0.030813 -0.124664  0.869120  0.816868  ...     0.833798     -1.0   \n",
       "1  -1.000000  0.243333  0.737403 -0.712605  ...    -0.505316     -1.0   \n",
       "2  -0.030813 -0.122597 -0.012335  0.003407  ...     0.003407     -1.0   \n",
       "3  -0.030813 -0.191234  0.332636  0.617838  ...    -0.624652     -1.0   \n",
       "4  -0.030813 -0.582799 -0.012335  0.003407  ...     0.003407     -1.0   \n",
       "\n",
       "    grltnoa  pchcapx_ia*dp_sp  aeavol*bm_sp  rd*tbl  sic_31  chatoia*dfy  \\\n",
       "0  0.643660          0.666391      0.762082    -1.0       0     0.728137   \n",
       "1  0.521923          0.870159      0.580752    -1.0       0     0.884432   \n",
       "2  0.002786          0.000000     -0.003717    -1.0       0     0.000000   \n",
       "3  0.002786         -0.513564      0.770756     1.0       0     0.871201   \n",
       "4  0.002786          0.000000     -0.003717    -1.0       0     0.000000   \n",
       "\n",
       "      mom6m   egr*tbl  \n",
       "0  0.396464 -0.506555  \n",
       "1 -0.225059 -0.926912  \n",
       "2 -0.372273  0.003407  \n",
       "3  0.041249 -0.629194  \n",
       "4  0.305903  0.003407  \n",
       "\n",
       "[5 rows x 920 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb346fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_turn*ep_sp</th>\n",
       "      <th>roeq</th>\n",
       "      <th>sic_40</th>\n",
       "      <th>cashpr*svar</th>\n",
       "      <th>ep*ep_sp</th>\n",
       "      <th>chtx*ep_sp</th>\n",
       "      <th>nincr*tms</th>\n",
       "      <th>beta*tms</th>\n",
       "      <th>age*tbl</th>\n",
       "      <th>hire*dfy</th>\n",
       "      <th>...</th>\n",
       "      <th>chempia*tms</th>\n",
       "      <th>sin*tbl</th>\n",
       "      <th>grltnoa</th>\n",
       "      <th>pchcapx_ia*dp_sp</th>\n",
       "      <th>aeavol*bm_sp</th>\n",
       "      <th>rd*tbl</th>\n",
       "      <th>sic_31</th>\n",
       "      <th>chatoia*dfy</th>\n",
       "      <th>mom6m</th>\n",
       "      <th>egr*tbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.799819</td>\n",
       "      <td>-0.002491</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.013764</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>-0.063098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00287</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002643</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.272535</td>\n",
       "      <td>-0.002491</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.547110</td>\n",
       "      <td>0.845108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.013764</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00287</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002643</td>\n",
       "      <td>0.801830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.364787</td>\n",
       "      <td>-0.002491</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.013764</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>-0.063098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00287</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002643</td>\n",
       "      <td>0.577944</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.856195</td>\n",
       "      <td>-0.002491</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.013764</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>-0.063098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00287</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002643</td>\n",
       "      <td>0.197186</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.955984</td>\n",
       "      <td>-0.002491</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.013764</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>-0.063098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00287</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002643</td>\n",
       "      <td>-0.724227</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 920 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   std_turn*ep_sp      roeq  sic_40  cashpr*svar  ep*ep_sp  chtx*ep_sp  \\\n",
       "0        0.799819 -0.002491       0     0.003098 -0.003098         0.0   \n",
       "1        0.272535 -0.002491       0    -0.547110  0.845108         0.0   \n",
       "2       -0.364787 -0.002491       0     0.003098 -0.003098         0.0   \n",
       "3        0.856195 -0.002491       0     0.003098 -0.003098         0.0   \n",
       "4       -0.955984 -0.002491       0     0.003098 -0.003098         0.0   \n",
       "\n",
       "   nincr*tms  beta*tms   age*tbl  hire*dfy  ...  chempia*tms  sin*tbl  \\\n",
       "0  -0.013764  0.003402 -0.063098       0.0  ...     -0.00287     -1.0   \n",
       "1  -0.013764  0.003402 -1.000000       0.0  ...     -0.00287     -1.0   \n",
       "2  -0.013764  0.003402 -0.063098       0.0  ...     -0.00287     -1.0   \n",
       "3  -0.013764  0.003402 -0.063098       0.0  ...     -0.00287     -1.0   \n",
       "4  -0.013764  0.003402 -0.063098       0.0  ...     -0.00287     -1.0   \n",
       "\n",
       "   grltnoa  pchcapx_ia*dp_sp  aeavol*bm_sp  rd*tbl  sic_31  chatoia*dfy  \\\n",
       "0      0.0          0.002794     -0.000075    -1.0       0    -0.002643   \n",
       "1      0.0          0.002794     -0.000075    -1.0       0    -0.002643   \n",
       "2      0.0          0.002794     -0.000075    -1.0       0    -0.002643   \n",
       "3      0.0          0.002794     -0.000075    -1.0       0    -0.002643   \n",
       "4      0.0          0.002794     -0.000075    -1.0       0    -0.002643   \n",
       "\n",
       "      mom6m  egr*tbl  \n",
       "0 -1.000000      0.0  \n",
       "1  0.801830      0.0  \n",
       "2  0.577944      0.0  \n",
       "3  0.197186      0.0  \n",
       "4 -0.724227      0.0  \n",
       "\n",
       "[5 rows x 920 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457ffa7",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Random Forest\n",
    "# This takes too long to run\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=300, max_depth=6, max_features=100).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df70218",
   "metadata": {},
   "source": [
    "# Apply NN and OLS_3 Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e87c21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define customized R^2 according to the paper; this is not the usual definition\n",
    "# This R^2 will be larger than the usual R^2\n",
    "def R_squared(y_true, y_pred):\n",
    "    resid = tf.square(y_true - y_pred)\n",
    "    denom = tf.square(y_true)\n",
    "    return 1 - tf.divide(tf.reduce_sum(resid), tf.reduce_sum(denom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd6d87d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error#, r2_score\n",
    "\n",
    "# OLS with preselected size, bm, and momentum covariates\n",
    "features_3 = ['mvel1','bm','mom1m']\n",
    "OLS_3 = LinearRegression().fit(x_train[features_3], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "147af529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize to record all OLS_3 results\n",
    "OLS_3_train_mse = []\n",
    "OLS_3_val_mse = []\n",
    "OLS_3_test_mse = []\n",
    "OLS_3_train_R2 = []\n",
    "OLS_3_val_R2 = []\n",
    "OLS_3_test_R2 = []\n",
    "\n",
    "OLS_3_test_t_mse = []\n",
    "OLS_3_test_t_R2 = []\n",
    "\n",
    "OLS_3_test_b_mse = []\n",
    "OLS_3_test_b_R2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f479291e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total training set has MSE 0.015894677700940815\n",
      "The total validation set has MSE 0.02657529108184017\n",
      "The total test set has MSE 0.0362750727239179\n",
      "The total training set has r^2 0.003989748312871355\n",
      "The total validation set has r^2 -0.001847618702224274\n",
      "The total test set has r^2 0.0020615522965783395\n",
      "\n",
      "The top 1k test set has MSE 0.015601747395857894\n",
      "The top 1k test set has r^2 -0.0020383520128555155\n",
      "\n",
      "The bottom 1k test set has MSE 0.08297433207552728\n",
      "The bottom 1k test set has r^2 0.0011847044500689075\n"
     ]
    }
   ],
   "source": [
    "OLS_3_train_mse.append(mean_squared_error(y_train, OLS_3.predict(x_train[features_3])))\n",
    "OLS_3_val_mse.append(mean_squared_error(y_val, OLS_3.predict(x_val[features_3])))\n",
    "OLS_3_test_mse.append(mean_squared_error(y_test, OLS_3.predict(x_test[features_3])))\n",
    "OLS_3_train_R2.append(R_squared(y_train, OLS_3.predict(x_train[features_3])))\n",
    "OLS_3_val_R2.append(R_squared(y_val, OLS_3.predict(x_val[features_3])))\n",
    "OLS_3_test_R2.append(R_squared(y_test, OLS_3.predict(x_test[features_3])))\n",
    "\n",
    "OLS_3_test_t_mse.append(mean_squared_error(y_test_t, OLS_3.predict(x_test_t[features_3])))\n",
    "OLS_3_test_t_R2.append(R_squared(y_test_t, OLS_3.predict(x_test_t[features_3])))\n",
    "\n",
    "OLS_3_test_b_mse.append(mean_squared_error(y_test_b, OLS_3.predict(x_test_b[features_3])))\n",
    "OLS_3_test_b_R2.append(R_squared(y_test_b, OLS_3.predict(x_test_b[features_3])))\n",
    "\n",
    "print(f'The total training set has MSE {mean_squared_error(y_train, OLS_3.predict(x_train[features_3]))}')\n",
    "print(f'The total validation set has MSE {mean_squared_error(y_val, OLS_3.predict(x_val[features_3]))}')\n",
    "print(f'The total test set has MSE {mean_squared_error(y_test, OLS_3.predict(x_test[features_3]))}')\n",
    "print(f'The total training set has r^2 {R_squared(y_train, OLS_3.predict(x_train[features_3]))}')\n",
    "print(f'The total validation set has r^2 {R_squared(y_val, OLS_3.predict(x_val[features_3]))}')\n",
    "print(f'The total test set has r^2 {R_squared(y_test, OLS_3.predict(x_test[features_3]))}\\n')\n",
    "\n",
    "print(f'The top 1k test set has MSE {mean_squared_error(y_test_t, OLS_3.predict(x_test_t[features_3]))}')\n",
    "print(f'The top 1k test set has r^2 {R_squared(y_test_t, OLS_3.predict(x_test_t[features_3]))}\\n')\n",
    "\n",
    "print(f'The bottom 1k test set has MSE {mean_squared_error(y_test_b, OLS_3.predict(x_test_b[features_3]))}')\n",
    "print(f'The bottom 1k test set has r^2 {R_squared(y_test_b, OLS_3.predict(x_test_b[features_3]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c0dff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "# Import the class NN from NN_implementations\n",
    "from ipynb.fs.defs.NN_implementations import NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34dca5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "963f0e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record annual results (30, 3) = (year, model)\n",
    "loss_train = np.zeros((30, 3))\n",
    "loss_val = np.zeros((30, 3))\n",
    "loss_test = np.zeros((30, 3))\n",
    "loss_test_t = np.zeros((30, 3))\n",
    "loss_test_b = np.zeros((30, 3))\n",
    "R2_train = np.zeros((30, 3))\n",
    "R2_val = np.zeros((30, 3))\n",
    "R2_test = np.zeros((30, 3))\n",
    "R2_test_t = np.zeros((30, 3))\n",
    "R2_test_b = np.zeros((30, 3))\n",
    "\n",
    "# Dictionary keys are 'year_model' (e.g. '1975_0' means training till 1975 and validation starts on 1975)\n",
    "y_train_pred_dict = {}\n",
    "y_val_pred_dict = {}\n",
    "# Dictionary keys are 'year_model' (e.g. '1987_0' means the first model testing 1987)\n",
    "y_pred_dict = {}\n",
    "y_pred_t_dict = {}\n",
    "y_pred_b_dict = {}\n",
    "\n",
    "# Record monthly results (30, 12, 3) = (year, month, model)\n",
    "loss_testM = np.zeros((30, 12, 3))\n",
    "loss_test_tM = np.zeros((30, 12, 3))\n",
    "loss_test_bM = np.zeros((30, 12, 3))\n",
    "R2_testM = np.zeros((30, 12, 3))\n",
    "R2_test_tM = np.zeros((30, 12, 3))\n",
    "R2_test_bM = np.zeros((30, 12, 3))\n",
    "\n",
    "# Dictionary keys are 'year_month_model' (e.g. '1987_0_3' means the fourth model testing Jan 1987)\n",
    "y_predM_dict = {}\n",
    "y_pred_tM_dict = {}\n",
    "y_pred_bM_dict = {}\n",
    "\n",
    "# Specify the hyperparameters\n",
    "L1_val = 0\n",
    "L2_val = 0.01\n",
    "dropout = 0\n",
    "lr_val = 1e-3\n",
    "bs_val = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6033a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile 10 models for ensemble later\n",
    "model_dict = {}\n",
    "for i in range(3):\n",
    "    seed_val = 120 + i\n",
    "    model_dict[str(i)] = model.call(\n",
    "                                model_input = keras.layers.Input(shape=(920, )),\n",
    "                                n_layers = 3,\n",
    "                                layers_dim = [32, 16, 8],\n",
    "                                activation = 'relu',\n",
    "                                BatchNormalization = True,\n",
    "                                L1_lambda = L1_val,\n",
    "                                L2_lambda = L2_val,\n",
    "                                dropout_rate = dropout,\n",
    "                                seed = seed_val)\n",
    "    model_dict[str(i)].compile(\n",
    "        loss = keras.losses.MeanSquaredError(),\n",
    "        optimizer=keras.optimizers.Adam(lr_val),\n",
    "        metrics=[R_squared]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62140c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b479d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_val = np.datetime64('1975-01-31')\n",
    "start_test = np.datetime64('1987-01-31')\n",
    "end_test = np.datetime64('1987-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed35e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide stocks into deciles according to y_predM and use y_testM to calculate annualized Sharpe ratio\n",
    "def make_decile(x_testM, y_testM, y_predM):\n",
    "    x_testM = pd.concat([x_testM, y_testM, y_predM], axis=1)\n",
    "    x_testM['DistinctRank'] = x_testM.Pred(method='first')\n",
    "    x_testM_grouped = x_testM.groupby(pd.qcut(x_testM.DistinctRank, 10, labels=False))\n",
    "\n",
    "    # decile['0'] is lowest decile, decile['9'] highest\n",
    "    decile = {}\n",
    "    for key, group in x_testM_grouped:\n",
    "        decile[str(key)] = pd.DataFrame(group).sort_values(by=['Pred'], ascending=False, ignore_index=True)\n",
    "            \n",
    "    pred = []\n",
    "    std = []\n",
    "    avg = []\n",
    "    Sharpe = []\n",
    "    for i in range(10): # 10 deciles\n",
    "        pred.append(np.mean(decile[str(i)]['Pred']))\n",
    "        avg.append(np.mean(decile[str(i)]['RET'])*12)\n",
    "        std.append(np.std(decile[str(i)]['RET'])*sqrt(12))\n",
    "        Sharpe.append(avg[-1] / std[-1])\n",
    "            \n",
    "    return pred, avg, std, Sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "# Use start years for naming keys in prediction dictionaries\n",
    "start_val_year = 1975\n",
    "start_test_year = 1987\n",
    "# Construct monthly start and end dates for test set\n",
    "start_test_ym = '1987-01'\n",
    "end_test_ym = '1988-02'\n",
    "all_months = np.arange(start_test_ym, end_test_ym, dtype='datetime64[M]').astype('datetime64[D]')\n",
    "\n",
    "for i in range(3): # i is model\n",
    "    # Housekeeping\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # Train the model\n",
    "    history = model_dict[str(i)].fit(x_train, y_train, validation_data = (x_val, y_val),\n",
    "                               # change batch_size and epoch\n",
    "                               batch_size=bs_val, epochs=100\n",
    "                               # optional early stop\n",
    "                               ,callbacks=[earlystop]\n",
    "                               )\n",
    "    \n",
    "    # Save weights of all models for all years\n",
    "    # e.g. 'weights_1987_0' means the first model weights when the test set starts on 1987, so training ends on 1987-13=1974\n",
    "    # model_dict[str(i)].save_weights(f'Results_log\\\\seed129_{start_test_year}_' + str(i) + '.h5')\n",
    "    \n",
    "    # Find model predictions for entire/top/bottom\n",
    "    y_train_pred_dict[f'{start_val_year}_' + str(i)] = model_dict[str(i)].predict(x_train, batch_size=x_train.shape[0])\n",
    "    y_val_pred_dict[f'{start_val_year}_' + str(i)] = model_dict[str(i)].predict(x_val, batch_size=x_val.shape[0])\n",
    "    y_pred_dict[f'{start_test_year}_' + str(i)] = model_dict[str(i)].predict(x_test, batch_size=x_test.shape[0])\n",
    "    y_pred_t_dict[f'{start_test_year}_' + str(i)] = model_dict[str(i)].predict(x_test_t, batch_size=x_test_t.shape[0])\n",
    "    y_pred_b_dict[f'{start_test_year}_' + str(i)] = model_dict[str(i)].predict(x_test_b, batch_size=x_test_b.shape[0])\n",
    "    predY, avgY, stdY, SharpeY = make_decile(x_test, y_test, pd.DataFrame(y_pred_dict[f'{start_test_year}_' + str(i)]), columns=['Pred'])\n",
    "    performace = pd.DataFrame(data={'Pred': pred, 'Avg': avg, 'Std': std, 'SR': Sharpe})\n",
    "    print(performance)\n",
    "        \n",
    "    # Record loss and R^2: train and validation\n",
    "    loss_train[0, i] = mse(y_train, y_train_pred_dict[f'{start_val_year}_' + str(i)])\n",
    "    R2_train[0, i] = R_squared(y_train, y_train_pred_dict[f'{start_val_year}_' + str(i)])\n",
    "    loss_val[0, i] = mse(y_val, y_val_pred_dict[f'{start_val_year}_' + str(i)])\n",
    "    R2_val[0, i] = R_squared(y_val, y_val_pred_dict[f'{start_val_year}_' + str(i)])\n",
    "    # Record loss and R^2: test, top/bottom test\n",
    "    loss_test[0, i] = mse(y_test, y_pred_dict[f'{start_test_year}_' + str(i)])\n",
    "    R2_test[0, i] = R_squared(y_test, y_pred_dict[f'{start_test_year}_' + str(i)])\n",
    "    loss_test_t[0, i] = mse(y_test_t, y_pred_t_dict[f'{start_test_year}_' + str(i)])\n",
    "    R2_test_t[0, i] = R_squared(y_test_t, y_pred_t_dict[f'{start_test_year}_' + str(i)])\n",
    "    loss_test_b[0, i] = mse(y_test_b, y_pred_b_dict[f'{start_test_year}_' + str(i)])\n",
    "    R2_test_b[0, i] = R_squared(y_test_b, y_pred_b_dict[f'{start_test_year}_' + str(i)]) \n",
    "    \n",
    "    decile = {}\n",
    "    std = {}\n",
    "    avg = {}\n",
    "    Sharpe = {}\n",
    "    for j in range(12): # j is month\n",
    "        # Get entire, top, and bottom test sets\n",
    "        start_testM = all_months[j]\n",
    "        end_testM = all_months[j+1]\n",
    "        x_testM, y_testM, x_test_tM, y_test_tM, x_test_bM, y_test_bM = interactions(\n",
    "                                                data[(data['DATE'] >= start_testM) & (data['DATE'] <= end_testM)],\n",
    "                                                data_ma[(data_ma['yyyymm'] >= start_testM) & (data_ma['yyyymm'] <= end_testM)],\n",
    "                                                characteristics, ma_predictors)\n",
    "        \n",
    "        # Find model predictions for entire/top/bottom WITHOUT batch_size\n",
    "        y_predM_dict[f'{start_test_year}_' + str(j) + '_' + str(i)] = model_dict[str(i)].predict(x_testM, batch_size=x_testM.shape[0])\n",
    "        y_pred_tM_dict[f'{start_test_year}_' + str(j) + '_' + str(i)] = model_dict[str(i)].predict(x_test_tM, batch_size=x_test_tM.shape[0])\n",
    "        y_pred_bM_dict[f'{start_test_year}_' + str(j) + '_' + str(i)] = model_dict[str(i)].predict(x_test_bM, batch_size=x_test_bM.shape[0])\n",
    "        \n",
    "        # Rename for easier reference later; RET is excess return\n",
    "        y_predM = pd.DataFrame(y_predM_dict[f'{start_test_year}_' + str(j) + '_' + str(i)], columns=['Pred'])\n",
    "        y_pred_tM = pd.DataFrame(y_pred_tM_dict[f'{start_test_year}_' + str(j) + '_' + str(i)], columns=['Pred'])\n",
    "        y_pred_bM = pd.DataFrame(y_pred_bM_dict[f'{start_test_year}_' + str(j) + '_' + str(i)], columns=['Pred'])\n",
    "        \n",
    "        # Record loss and R^2\n",
    "        loss_testM[0, j, i] = mse(y_testM, y_predM)\n",
    "        R2_testM[0, j, i] = R_squared(y_testM, y_predM)\n",
    "        loss_test_tM[0, j, i] = mse(y_test_tM, y_pred_tM)\n",
    "        R2_test_tM[0, j, i] = R_squared(y_test_tM, y_pred_tM)\n",
    "        loss_test_bM[0, j, i] = mse(y_test_bM, y_pred_bM)\n",
    "        R2_test_bM[0, j, i] = R_squared(y_test_bM, y_pred_bM)  \n",
    "    \n",
    "        pred, std, avg, Sharpe = make_decile(x_testM, y_testM, y_predM)\n",
    "        performace = pd.DataFrame(data={'Pred': pred, 'Avg': avg, 'Std': std, 'SR': Sharpe})\n",
    "        performace.to_csv(f'Results_log\\\\{start_test_year}_perf.csv', mode='a')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SR_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68b3ee",
   "metadata": {},
   "source": [
    "# Recursively do OLS_3 and refit NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec62049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime64(date_digits):\n",
    "    date_str = str(date_digits)\n",
    "    date_str = date_str[0:4] + '-' + date_str[4:6] + '-' + date_str[6:8]\n",
    "    return date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed91e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_val = np.datetime64('1975-01-31')\n",
    "# start_test = np.datetime64('1987-01-31')\n",
    "# end_test = np.datetime64('1987-12-31')\n",
    "start_test_year = 1987\n",
    "end_test_year = 1988\n",
    "start_val_numer = 19750131\n",
    "start_test_numer = 19870131\n",
    "end_test_numer = 19871231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92abdc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the sizes of training, validation, test sets\n",
    "train_shape = [0]*30\n",
    "val_shape = [0]*30\n",
    "test_shape = [0]*30\n",
    "train_shape[0] = 479467\n",
    "val_shape[0] = 773887\n",
    "test_shape[0] = 83323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb115130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There are in total 30 OOS years to test (1987-2016)\n",
    "# Train every year, but test every month and every year\n",
    "for year in range(1, 30):\n",
    "    \n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # Set the correct dates\n",
    "    start_val_prev_numer = start_val_numer\n",
    "    start_test_prev_numer = start_test_numer\n",
    "    end_test_prev_numer = end_test_numer\n",
    "    start_val_numer = start_val_numer + 10000\n",
    "    start_test_numer = start_test_numer + 10000\n",
    "    end_test_numer = end_test_numer + 10000\n",
    "    start_val_prev = get_datetime64(start_val_prev_numer)\n",
    "    start_test_prev = get_datetime64(start_test_prev_numer)\n",
    "    end_test_prev = get_datetime64(end_test_prev_numer)\n",
    "    start_val = get_datetime64(start_val_numer)\n",
    "    start_test = get_datetime64(start_test_numer)\n",
    "    end_test = get_datetime64(end_test_numer)\n",
    "    print(start_val_prev, start_test_prev, end_test_prev, start_val, start_test, end_test)\n",
    "    \n",
    "    # Add one more year to training\n",
    "    x_train_add, y_train_add, _, _, _, _ = interactions(data[(data['DATE'] < start_val) & (data['DATE'] >= start_val_prev)],\n",
    "                                           data_ma[(data_ma['yyyymm'] < start_val) & (data_ma['yyyymm'] >= start_val_prev)],\n",
    "                                           characteristics, ma_predictors)\n",
    "    x_train = pd.concat([x_train, x_train_add], ignore_index=True)\n",
    "    y_train = pd.concat([y_train, y_train_add], ignore_index=True)\n",
    "    train_shape[year] = x_train.shape[0]\n",
    "    \n",
    "    # Since x,y_val has no more date inside, we will just get them again\n",
    "    x_val, y_val, _, _, _, _ = interactions(data[(data['DATE'] < start_test) & (data['DATE'] >= start_val)],\n",
    "                                                                    data_ma[(data_ma['yyyymm'] < start_test) & (data_ma['yyyymm'] >= start_val)],\n",
    "                                                                    characteristics, ma_predictors)\n",
    "    val_shape[year] = x_val.shape[0]\n",
    "\n",
    "    # Change the test set to the next year\n",
    "    x_test, y_test, x_test_t, y_test_t, x_test_b, y_test_b = interactions(data[(data['DATE'] >= start_test) & (data['DATE'] <= end_test)],\n",
    "                                                                          data_ma[(data_ma['yyyymm'] >= start_test) & (data_ma['yyyymm'] <= end_test)],\n",
    "                                                                          characteristics, ma_predictors)\n",
    "    test_shape[year] = x_test.shape[0]\n",
    "    \n",
    "    # Do OLS_3 first\n",
    "    # Replace the OLS model every iteration (could put in dictionary if want to save all 30 of them)\n",
    "    OLS_3 = LinearRegression().fit(x_train[features_3], y_train)\n",
    "    \n",
    "    OLS_3_train_mse.append(mean_squared_error(y_train, OLS_3.predict(x_train[features_3])))\n",
    "    OLS_3_val_mse.append(mean_squared_error(y_val, OLS_3.predict(x_val[features_3])))\n",
    "    OLS_3_test_mse.append(mean_squared_error(y_test, OLS_3.predict(x_test[features_3])))\n",
    "    OLS_3_train_R2.append(R_squared(y_train, OLS_3.predict(x_train[features_3])))\n",
    "    OLS_3_val_R2.append(R_squared(y_val, OLS_3.predict(x_val[features_3])))\n",
    "    OLS_3_test_R2.append(R_squared(y_test, OLS_3.predict(x_test[features_3])))\n",
    "    \n",
    "    #OLS_3_val_t_mse.append(mean_squared_error(y_val_t, OLS_3.predict(x_val_t[features_3])))\n",
    "    OLS_3_test_t_mse.append(mean_squared_error(y_test_t, OLS_3.predict(x_test_t[features_3])))\n",
    "    #OLS_3_val_b_mse.append(mean_squared_error(y_val_b, OLS_3.predict(x_val_b[features_3])))\n",
    "    OLS_3_test_b_mse.append(mean_squared_error(y_test_b, OLS_3.predict(x_test_b[features_3])))\n",
    "    #OLS_3_train_t_R2_demeaned.append(r2_score(y_train_t, OLS_3.predict(x_train_t[features_3])))\n",
    "    #OLS_3_train_t_R2.append(R_oos(y_train_t, OLS_3.predict(x_train_t[features_3])))\n",
    "    #OLS_3_val_t_R2.append(R_oos(y_val_t, OLS_3.predict(x_val_t[features_3])))\n",
    "    OLS_3_test_t_R2.append(R_squared(y_test_t, OLS_3.predict(x_test_t[features_3])))\n",
    "    #OLS_3_val_b_R2.append(R_oos(y_val_b, OLS_3.predict(x_val_b[features_3])))\n",
    "    OLS_3_test_b_R2.append(R_squared(y_test_b, OLS_3.predict(x_test_b[features_3])))\n",
    "    print(OLS_3_train_R2[-1], OLS_3_val_R2[-1],  OLS_3_val_t_R2[-1], OLS_3_val_b_R2[-1], OLS_3_test_R2[-1], OLS_3_test_t_R2[-1], \n",
    "         OLS_3_test_b_R2[-1])\n",
    "    \n",
    "    for i in range(10):\n",
    "        # Housekeeping\n",
    "        keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        # This refits the model used before\n",
    "        history = model_dict[str(i)].fit(x_train, y_train, validation_data = (x_val, y_val),\n",
    "                               # change batch_size and epoch\n",
    "                               batch_size=bs_val, epochs=100\n",
    "                               # optional early stop\n",
    "                               ,callbacks=[earlystop]\n",
    "                               )\n",
    "    \n",
    "        loss_val_t[year, i], R2_val_t[year, i] = model_dict[str(i)].evaluate(x_val_t, y_val_t, batch_size=bs_val)\n",
    "        loss_val_b[year, i], R2_val_b[year, i] = model_dict[str(i)].evaluate(x_val_b, y_val_b, batch_size=bs_val)\n",
    "        loss_test[year, i], R2_test[year, i] = model_dict[str(i)].evaluate(x_test, y_test, batch_size=bs_val)\n",
    "        loss_test_t[year, i], R2_test_t[year, i] = model_dict[str(i)].evaluate(x_test_t, y_test_t, batch_size=bs_val)\n",
    "        loss_test_b[year, i], R2_test_b[year, i] = model_dict[str(i)].evaluate(x_test_b, y_test_b, batch_size=bs_val)\n",
    "\n",
    "    #print(loss_val_t[year, :], loss_val_b[year, :], loss_test[year, :], loss_test_t[year, :], loss_test_b[year, :])\n",
    "    print(R2_val_t[year, :], R2_val_b[year, :], R2_test[year, :], R2_test_t[year, :], R2_test_b[year, :])    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some references for model.evaluate()\n",
    "# https://stackoverflow.com/questions/50723287/meaning-of-batch-size-in-model-evaluate (floating point error)\n",
    "# https://stackoverflow.com/questions/49359489/how-are-metrics-computed-in-keras (val metric)\n",
    "\n",
    "print(OLS_3_train_R2)\n",
    "print(OLS_3_val_R2)\n",
    "print(OLS_3_val_t_R2)\n",
    "print(OLS_3_val_b_R2)\n",
    "print(OLS_3_test_R2)\n",
    "print(OLS_3_test_t_R2)\n",
    "print(OLS_3_test_b_R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755bbc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R2_val_t[0:12, :])\n",
    "print(R2_val_b[0:12, :])\n",
    "print(R2_test[0:12, :])\n",
    "print(R2_test_t[0:12, :])\n",
    "print(R2_test_b[0:12, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model_dict[str(i)].save_weights(f'model_weights_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict['9'].evaluate(x_val_t, y_val_t, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc38a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(R2_test[0:12,:], axis=1) - np.array(OLS_3_test_R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b8733",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(R2_test_t[0:12,:], axis=1) - np.array(OLS_3_test_t_R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726149bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(R2_test_b[0:12,:], axis=1) - np.array(OLS_3_test_b_R2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
